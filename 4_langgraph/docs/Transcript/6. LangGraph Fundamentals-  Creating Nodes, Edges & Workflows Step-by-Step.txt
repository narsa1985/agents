Refer : D:\MyProjects\agents\4_langgraph\1_lab1.ipynb

So here we are looking at our node creation.

Remember a node is a function.

So we're going to create a function.

It's called our first node.

It takes an old state and it returns a new state.

Its states are immutable as we say.

And so we are not going to do anything.

We're not going to come and mutate old state.

In fact, you may see from the way that it's grayed out here that we don't actually touch Old State,

which is unusual, but just for this example.

So what are we actually going to do?

So we're going to make a string called reply.

And that reply is going to be some random word choice of a noun.

And then the word r and then a random choice of an adjective.

And we're going to create one of these kinds of message structures and OpenAI familiar message structure

and put that into messages.

We're going to say that the new state is R another a new state class.

We're going to instantiate it passing in this messages.

And we are going to return that the new state.

And that is the end of our first node.

And we then call graph dot add node.

This is how we officially add it to the graph that is being built.

We give it a name, we call it first node and we pass in the function the function that represents the

node called our first node.

Okay.

So we're going to run that cell.

And now we're coming on to look at creating our edges.

So you can see here that I now call Graph Builder add edge to add a couple of edges.

And you'll see that these words start and end there.

So what are they.

Well these are things that we've imported at the top in from graph graph.

They are constants start and end.

And of course they signify the beginning of our workflow and the end of it.

And so here what we say is we want an edge to take us from the start to our first node.

And then we want another edge to go from the first node to the end.

Okay, that sounds logical doesn't it?

So we'll run that.

And now with that we get to step five which you'll remember is compiling the graph.

It's saying we're done.

This is our workflow.

And we can now display it.

This is rather nice a quick way to show visually what it is we're talking about.

And hopefully this will be no surprise.

We've got a start going into our first node going into our end.

What could be easier?

That's lovely.

Okay, so we've done the five steps, which is of course the what the first part of running a graph

system.

We've compiled our graph and we've done it by adding nodes and edges.

It's now time to run it.

Okay.

And what we're going to do is to run it.

We're going to create a gradio chat function.

Why not.

Remember gradio chat functions take the user's current input and the history of prior inputs, and it's

meant to respond with the next output.

That's just what you do with a gradio chat function that we're going to pass into gradients chat interface

right there.

So that's what we have to do.

So what do we want to do.

Well, we're going to turn the message into a standard OpenAI format and put that into a message.

We're then going to create a state object with that as the is the message.

We are then going to invoke our graph.

And this is the key long chain word invoke.

You may be familiar.

Sorry I said long chain.

It's the graph word invoke.

But you may be familiar with it because it's the word in long chain as well.

So you invoke a graph in land graph with the state in order to get the result.

And that's what's going to execute our graph.

And what will come out will be the result.

And we will print it and we will also return it.

And that will come out of our chat function.

And so with that let's run this and see what happens.

Well we have a greater UI.

That's good.

Let's say hi there.

Muffins are haunted.

Is that so?

Penguins are sparkly.

You don't say penguins are outrageous.

For real.

Pickles are untrustworthy.

Ha ha ha.

You get the idea.

Uh, so, uh, this is the results of our small language model that is picking a random noun and adjective.

And I show you this.

If you're wondering what on earth are you doing?

I'm doing it to show that the graph setup has nothing to do with Llms necessarily.

The node is just a function, in this case a silly function, but it's a function there and it's taking

in a state and it's returning a state, and it doesn't need to have anything to do with llms.

Now down here, I'm printing the result of this.

And let me just show you that print statement.

Uh, we're printing what's coming back from calling invoke on the graph.

And I want to point out that that it may be something a bit different to what you're expecting because

it's not it's not messages with just a list of, of strings.

It's got a list of these things called human message, which you may know from, from Lang chain work.

It's like a, it's a construct to package things up.

And this is of course the result of the reducer running.

And when I said before that the reducer simply concatenates things into a list, I wasn't telling the

full story because it also does some of this packaging up that comes with Landgraf.

So if it just takes the text that's come back, it knows how to package it into a human message.

In terms of the things that I was saying and an AI message in terms of muffins or haunted and penguins

are sparkly and the like.

So that's this is some of the of the stuff hanging happening behind the scenes as a result of Landgraf,

which doesn't really matter to us.

We're taking advantage of that.

But we just wrote a simple, a super simple state.

Uh, super simple node.

We made a state that contained messages.

We made a node we take in an old state, we return a new state which is using this random sentence,

and it works.

We can invoke our graph and get a response, and we can have a conversation of rather one sided conversation

with a silly language model.

All right, let's do something more sensible.