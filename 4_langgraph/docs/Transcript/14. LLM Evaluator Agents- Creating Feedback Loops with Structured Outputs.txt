Refer : D:\MyProjects\agents\4_langgraph\4_lab4.ipynb

Because this is a day when we do two labs in one day.

Week four, day four preparing for tomorrow's big project, which is called the Sidekick.

And it's time to introduce structured outputs and a multi-agent flow.

So we've got a bunch of imports and we are going to set our dot env as usual.

And now we're going to be using structured outputs.

And you'll remember the first step with structured outputs is to define the schema.

What are we using to describe the results that must come back from an NLM.

And in particular, the thing that we're going to be working on is an evaluator, something which is

going to decide whether or not an answer from an LLM is good.

And so our evaluator is going to respond using this object in evaluator output.

Or really it's going to respond with JSON.

And the JSON is going to have to conform to this.

So we just describe what this means.

There's going to be a field feedback which is going to be feedback on the workers response.

Uh Success criteria.

Actually, let's change this to the assistance response because that's going to be more words that it

will understand.

Worker is what we will call it in this assist response.

There we go.

Now you get to see me type up.

So feedback on the assistance response success criteria is whether the success criteria has been met

and user input needed.

True.

If more input is needed from the user or clarifications, or if the assistant is stuck.

So this is going to allow we're going to have an evaluator that's going to evaluate the results of our

worker, the assistant, to use their terminology.

And it's going to decide whether it's okay to forward that back to the user, or whether it needs to

go back to the assistant for more work.

And one situation is if the success criteria are met and it's done its job.

But another situation is if the worker seems to be stuck or needs clarifications, in which case it

should return.

So there we go.

Um, okay.

And now to manage state.

You remember with state it can really be any Python object.

It can be a Pydantic object.

But we often use type dicts.

And that's what we're doing here.

And now for the first time, we have some real meaty information to store in the state.

We've always had messages before, but now we have a real state and we've got a bunch of things.

We do still have messages, which is representing the discussion between the user and the assistant,

but we've got other stuff which is going to represent the information being passed from the the evaluator.

Back to the thing.

I'm going to call the worker, the assistant.

Um, and so we're going to have some more stuff.

We're going to have success criteria, which is going to be set up front to define what does it mean

to be successful, feedback on the work that's going to come from the the worker.

And by the way, you use optional like this.

If this can be null, it can be none or it can be a string.

Success criteria met is a bool is true or false and is going to be true if the if there has been a successful

outcome that the criteria met and the the, it doesn't need to go back to the worker for more.

And user input needed is if we need to go back to the user to get some more information.

So that is our state.

So it's a much meatier state.

And this shows you that you can have whatever you want in the state.

The state is really up to you and the flow of your logic.

And that state is like something that has moved through the graph and everyone gets their opportunity.

Every node gets the state and gets its opportunity to to return a new state.

That is some change to that state.

And we're only specifying one reducer ad messages, which means that if one of these nodes returns with

some messages, they will get accumulated.

They will get concatenated with the existing messages.

But if one of these nodes returns user input needed, that will overwrite whatever was in the old state.

So when you return the new state, if you change one of these values here, that becomes the new setting

for anything that is downstream of you in the graph.

Okay.

So next up we set up our playwright tools.

This is the same code as before using the async browser, the playwright browser and the Playwright

Browser toolkit.

So we just run that.

That's pretty simple.

And now we're going to have two llms that we're going to initialize.

One of them is called the worker.

LLM plays the role of the assistant.

It's going to be GPT four mini.

And it's going to be bound to those tools so that it will automatically have the JSON gumpf in it.

And then separately we're going to have an evaluator LLM.

This is a separate LLM.

And it is we're setting it up.

Whereas before we said bind tools.

And now we say with structured output and pass in the Pydantic object.

And that means that the response will conform to this output.

Now not all models are set up to support structured output.

So you may find that some models can't do it if you're if you're going to be playing around with different

models.

If that is the case, of course, the alternative to this is to do it the old fashioned way, which

means instead of using structured outputs like this and passing a pedantic object, you ask the model

in the prompt to respond in JSON.

You give it the schema.

You give, you list out what kind of JSON it should respond in.

You maybe give a couple of examples to make sure that it's really biased to do well, and then you have

to parse that JSON in the response.

And that's all that is happening behind the scenes when we do structured outputs like this.

So that means you congratulations.

You now learn how to do structured outputs with graph.

It's that simple.

Okay.

So this is a bit of a long looking uh, function.

This node, the deaf worker which is representing our worker node, our assistant.

But it's only long because we've got a lot of prompting in here.

So it's a node.

And so as usual it takes a state and it's going to return a state.

And you can see it's returning something with messages.

And we know that messages accumulates because we have the reducer.

So that is going to add on more messages.

Okay.

So we've got like a long system message.

Let me talk you through it.

We say look you're a helpful assistant that can use tools to complete tasks.

You keep working on a task until either you have a question or clarification for the user, or the success

criteria has been met.

And this is the success criteria, and we take it from the state.

It's something that should be held in the state.

You should reply either with a question for the user about the assignment or with your final response.

If you have a question for the user, you need to reply by clearly stating your question.

An example might be this.

It's not super necessary for me to have done that, but I wanted to make it really clear that it will

say when it has a question and sort of force, force the point.

If you finished reply with the final answer and don't ask a question, simply reply with the answer.

And I say that because these models love to reply with things like can I help you with anything else?

And that then might confuse our evaluator that's looking to see if it needs help.

So I want it to be super clear on this front.

Okay.

And of course all these things are subject for experimentation.

There's no hard and fast rules.

It's not like that is a as a rule that you have to put this in the prompt.

I hope you know this by now.

This is this is really the the the part of AI engineering that is about experimentation, R&D.

You can imagine I've been crafting this prompt for the last couple of hours.

So it's something that obviously you hone in on something that works well.

And you may find that particularly with different models or if you have different assignments, it's

something that you have to tweak to get the kind of performance you want anyways.

Uh, if, if we've got in our state something in this, in this field feedback on work, then that means

that an evaluation has happened and it's not gone well.

There's been feedback and it's come back for more.

So then we add to the system message.

Previously you thought you completed the assignment, but your reply was rejected because the success

criteria was not met.

Here is the feedback on why this was rejected.

And then we give the feedback.

And then with this feedback please continue the assignment ensuring you meet the success criteria.

Uh so there it is spelled out in detail.

Um, okay.

And then I've got here some, some slightly hokey code that that looks to see whether there's already

a system message inside there.

And if there already is, then it just replaces whatever system message is there with this system message.

If it doesn't find a system message, then, uh, it, uh, it creates a new one and puts it at the

front.

So this is, this is just to make sure that we handle those various scenarios.

Now, this is a little bit hokey because, uh, Landgraf will have already perhaps have built a system

message.

So, so we have to be a bit careful about this, and it might be worth doing some testing to make sure

that it works for different models.

Okay.

So at the end of all that we then call worker LM with tools and we invoke the messages.

We get back a response and that is what we then return.

So there we have it.

Uh, okay.

Now we now have something pretty interesting called the worker router.