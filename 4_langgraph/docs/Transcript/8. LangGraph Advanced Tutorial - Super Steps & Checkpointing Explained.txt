And a very warm welcome to week four, day three.

Here we are.

This is going to be the time that Landgraf is going to start to pay dividends.

The investment that we've made in understanding the new terminology is going to come together, and

we're going to see some real value.

But first, as always, I have to give you a quick recap.

Again, I'm going to get bored of it, but it's better that you get bored of it and you understand it.

So before you can call Graph Invoke, which is how you kick off your graph, you have to define it.

And defining it is these five steps to find your state class.

The graph Builder.

Create a node edges and compile the graph.

Just a quick refresher.

I'm sure you've got this all committed to memory now.

Okay, so what are we actually going to cover today?

Well, there's going to be a few ways we're going to go deeper into the world of graph.

First of all, we're going to look at Lang Smith and have a moment of understanding how information

gets logged there.

We're then going to look at tools tool calling something that we've done many times now using the out

of the box tools that come with Lang graph.

And then we're going to build a custom tool again as we've done many times.

So we'll see that working.

And we'll finally end with checkpointing which is a very important part of it.

Indeed.

And to to tee that up to motivate checkpointing.

I want to talk for a moment about something called the super step.

So what's a super step?

Well, a super step.

Start with a docs.

A super step.

They define as a single iteration over the graph nodes.

Nodes that run in parallel a part of the same super step.

Nodes that run sequentially belong to a separate super step.

So what does that mean exactly?

Now this is super, super important.

Super steps are super important.

And it's something which you have to get your head around.

And it's it's a it's a definitely may not be what you're expecting.

So a graph defines one set of interactions between like agents and their use of tools and perhaps delegating

to other agents.

If you think back to the handoff of, uh, OpenAI agents SDK.

So one invocation of the graph is just one kind of step.

It's like when the user says one message, putting that message to our LLM, that is one invocation

of the entire graph all the way through from top to bottom, and if then it comes back to the user with

a response and the user types in another message.

That's another invocation of the whole graph.

And each of these invocations is a superstep.

Every time you invoke the graph, that is a superstep.

And so yeah, it's important to get your head around it, because you might initially think that maybe

you could imagine that a node is like a human and a node is a chatbot, and that a graph is human and

chatbot going backwards and forwards.

But no, every time that there is that kind of human interaction, you should think of that as a whole

invocation of the graph.

Or in some situations, you might be resuming the graph from one point if it was paused for for a human

to respond.

So there's various ways of doing it, but each of these interactions is considered an entire superstep

within a superstep.

One one invocation of the graph belongs to to activities which happen in parallel as part of that step.

So this is a bit repetitive, but yeah, the graph describes one full superstep an interaction between

agents and tools and potentially multiple agents to achieve an outcome.

Every user interaction.

It's a fresh invoke call.

It's a fresh time that you're calling Graph Invoke.

There's also a graph resume.

But but the point remains.

It's a fresh call.

And the reducer that I talked about, the thing that is able to combine the state that comes out of

a call with the original state that applies during carrying out a single super step.

That is how state is managed across the graph.

That's how if multiple nodes update the same state state, it gets combined at the end.

That's what the reducer is handling.

But the reducer doesn't handle, uh, the separate super steps a separate super step is an entirely

fresh invocation of the graph.

So that's going to be a bit confusing.

So what does that mean to show that visually.

Next I want to draw you a diagram.

So with this diagram it's now all going to become crystal clear I'm confident it all begins with defining

the graph.

As I keep saying this is the five things you got to do, including defining the nodes, the edges,

and compiling the graph.

And then you're set.

The next thing you do is perhaps the user has a question, and that question is what you then use to

invoke the graph.

There you go.

And that is called a super step.

And out pops some kind of an answer after the agents and tools have done their thing, and then the

user says something, a follow up question, they have something else.

And that would be another super step.

And then that might happen again with another follow up or with another external activity.

Each of these are super steps, complete invocations of the graph.

So just to make that really obvious, I'm putting a little picture of a graph by each one.

The whole graph is is invoked each time.

And that is what it means to have a super step.

And why am I going on about this?

Because when it comes to memory, when it comes to preserving context between these different calls,

we need to involve something called checkpointing, which is something that landgraaf makes available

to us to be able to keep track, to sort of freeze a record of the state after each super step.

So we've got that tracked, and then next time we call a super step, it can recall the state exactly

as it was Checkpointed.

And that is one of the things that we're going to be doing in the lab right now.