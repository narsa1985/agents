Refer : D:\MyProjects\agents\4_langgraph\4_lab4.ipynb

So the worker router then is a Python function that we will use in our edge, in our conditional edge

to decide which way to route control.

And it's very simple.

It's going to take the most recent message.

It's going to see if it's a tool call.

If so it returns tools if not evaluator.

And that is to say that when our worker, our assistant has come up with an answer, if it's not involving

a tool call, then it needs to be evaluated.

And that's what we get to right now.

So for the evaluation, we have first of all, this little utility function format conversation that's

just used to take in.

I just wrote that to to transform a list of these message objects into something which says like user

assistant, user assistant in just a nice little text summary.

And you'll see why right now, as we come on to look at the evaluator code, we run these two cells

and we will talk about the evaluator.

So this is the evaluator.

This function right here.

It is a node.

It takes a state and it returns a state.

And it's meant to represent the LM, which is going to be assessing our our assistant, our worker,

and deciding if it's ready to return to the user or it needs to go back for more.

And so it all comes down to some prompting and let me take it through you, through it.

Remember that we're using structured outputs that will require that the model returns a particular type

of object.

So first we take the most recent response which is of course the assistance attempt.

We take that out of the state object the messages collection.

So then we come up with this system prompt.

You are an evaluator determines if a task has been completed successfully by an assistant.

Assess the last response based on the criteria.

Respond with your feedback and a decision on whether the success criteria is met and whether more input

is needed from the user and then the user message your.

This is going to be a bit more detailed.

You're evaluating a conversation between the user and the assistant.

You decide what action to take based on the last response from the assistant, the entire conversation

with the assistant along with the user's original request and all replies is here.

And this is going to use this little utility thing, which is just going to say like human, sorry,

not human.

It's going to say user assistant, user assistant with with the whole conversation so far.

So it's going to look very simple in language.

The success criteria for this assignment is and then I'm plucking out of the state this success criteria.

And as I hope you've guessed, this is something that's going to be set right at the very beginning

when we invoke the graph.

So that's going to be passed in by the user.

And it'll be maintained throughout our graph.

So we can pluck it out and just insert it in the user prompt for this evaluator right here.

And then I say the final response from the assistant that you were evaluating is this last response.

And of course that will already be included in here.

But I just want to be crystal clear so that the the evaluator understands that it's not assessing the

whole conversation, it's just assessing this response right here, which is what's going back to the

user.

Respond with your feedback and decide if the success criteria is met.

Also if more user input is required, either because the assistant has a question, needs clarification,

or seems to be stuck and unable to answer without help.

So you may remember that we already put some of this in the definition of the structured outputs of

the response, right up at the top.

Let me show you that right here in the evaluator output.

We already gave a little description of user input needed right here.

And so you may wonder why I'm repeating myself here.

And the answer is because there's never a harm in being repetitious with prompting.

Be clear.

Be instructive.

Repeat yourself.

These are good things to do in slightly different ways, because it biases the model to doing what we

want it to do.

Okay.

And then finally in here I put if we've already got some feedback in the state object, that means that

the evaluator was already called in this in this very loop and has already provided feedback in the

past.

And so I add in.

Also note that in a prior attempt from the assistant, assistance you provided this feedback.

If you're seeing the assistant repeating the same mistakes, then consider responding that user input

is required.

Now you might think this is very clever.

How did you come up with that and why?

Why that?

And when do I use this kind of thing?

And look, the answer is there's no magic here that is there.

Because I was testing this and it kept messing up by the evaluators, sending back the same problem

again and again.

And so this is the kind of thing that is trial and error.

You experiment, you try.

When something goes wrong, you change the prompt and you try some more.

There's no magic and no no clever rules to this.

This won't always apply, but it applies here.

And if you use a different model or slightly different tasks, you may find that you need to tweak this

or use something different.

And that is what AI engineering is all about.

And that is what what prompting is about.

And so yeah, the answer is it's research and development.

Okay.

We'll finish this off in just a second.

So we then put the system message and the user message, which is called a human message object, together

into one list called evaluator messages.

And it's confusing because we're using this concept of system message and user message in order to talk

to an evaluator.

And this isn't actually a human message, it's actually something where it's a user prompt, but it's

a message that we have manufactured.

But that's just really how you go about building system and user prompts using long chains constructs.

This is a a long chain construct within Landgraf.

Uh, and so, you know, this is a still achieving the same thing.

All right.

Now we then take our LM, which is the evaluator LM with structured outputs, we call invoke with these

messages.

And what comes back will be an instance of that class evaluator output.

It is that pedantic object filled up, uh, and behind the scenes what's going on is that it's been

asked to provide JSON and that JSON has come back and that JSON has been parsed into this object.

That's how it did it.

Uh, and so we're then going to create a new state because we're meant to return a new state, and in

that state we're going to respond.

We're going to add to the messages, because remember, messages has the reducer.

So whatever we reply here gets concatenated accumulated with the existing messages.

We're going to shove in there that the assistant is replying evaluator feedback on this answer and something

in there.

Then we're going to give some, some feedback.

Uh, we're going to uh, and so what we're doing here is we're taking the feedback from the Pydantic

object, and we're putting that in the state.

We're taking the success criteria from the Pydantic object, putting it in the state, taking user input

needed, taking it from the Pydantic.

The structured outputs that came back, put it in the state and return the new state.

Hopefully you followed all that.

If not, you will when it comes together.

And then we've got another of these router uh functions route based on evaluation, if the success criteria

is met or if user input is needed.

Then end the super step.

The super step is done.

It's got a controller.

It's got to pass back to the user.

In either of these two extremes, either we've done great or we've done horribly.

Either those extremes.

We need the user to get involved again.

But but if we didn't meet the success criteria and we don't need help from the user, then it needs

to be passed back to the worker.

We need to cycle back.

The worker has got to try again and improve on this.

Given this feedback, that is the whole idea.

That is the workflow.

And now we come to our graph.

It's very simple and all of this is pretty simple.

I've been making a bit of a meal out of it, explaining this step by step and talking about prompting,

but it's not that hard.

If you go through it yourself, you'll see what I mean.

So this is our graph.

We're going to add our worker node.

We're going to add our tools node and our evaluator node that we just built.

Now some edges we're going to have a conditional edge for the worker.

We're going to use the router that we wrote the worker router.

If it returns tools we're going to go with the node tools.

If it returns a value later, we'll pick the node evaluator.

We're going to add another an edge that goes from tools back to worker.

Again.

Remember this one.

When the tools finishes, it's got a route back to the worker.

That's kind of hokey that you have to do that.

You think it would sort of be be done automatically for you.

But but you have to be clear.

And then another conditional edge from the evaluator based on its evaluation, if it wants to go to

the worker, we put it back to the worker.

If we're done, we're done.

And then we also add a start edge to bring us, first of all to the worker.

Let's run that and look at a picture of this.

There it is.

There it is.

We have ourselves a true agentic workflow.

Um, there's the start goes to a worker that optionally can run tools, which has to come back.

There's a thick line, optionally a dotted line, an optional edge.

A conditional edge is the word sorry.

It will run a tool and then it will definitely come back an edge.

And then when it's done, this is shown as a conditional because it's only if it hasn't decided to run

a tool, then it will come this way and the evaluator chooses either to end in two situations.

Either success criteria is met or user feedback is required, and if not, it comes back to the worker

and or back to the worker.

So this this diagram hopefully has everything coming together for you.

And now scroll back up in the lab and just take a look through those nodes again.

And at this point it should be like oh got it, got it, got it, got it.

And hopefully you'll see that although I made a bit of a meal out of it, it is actually quite quick

to build something like this.

And you see one of Anthropics agentic patterns loud and clear here, although it's a little bit more

than one of their workflows because this has like an infinite loop in it, it can keep going.

And there's a lot of optionality here.

So this is a true agent pattern because in theory this could just keep running and running.

And it has some sort of agency autonomy over what it does.

And surely you're now thinking, well, I want to see this thing and that is what we will do next.