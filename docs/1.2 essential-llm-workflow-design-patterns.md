# Essential LLM Workflow Design Patterns

**Simple Guide for Interviews & Real-World Projects**

---

## Overview

There are 5 workflow patterns and 1 agent pattern for building AI systems. Workflows have fixed steps. Agents are flexible and make their own decisions.

---

# 1. Prompt Chaining

## Diagram

```
Input → [LLM 1] → [Code] → [LLM 2] → [Code] → [LLM 3] → Output
         Step 1            Step 2            Step 3
```

**Visual Flow:**
```
Patient Question
      ↓
┌─────────────┐
│   LLM 1     │  Analyze symptoms
│  (Analyzer) │
└──────┬──────┘
       ↓
  [Optional Code Processing]
       ↓
┌─────────────┐
│   LLM 2     │  Assess urgency
│ (Evaluator) │
└──────┬──────┘
       ↓
  [Optional Code Processing]
       ↓
┌─────────────┐
│   LLM 3     │  Create action plan
│  (Planner)  │
└──────┬──────┘
       ↓
  Final Answer
```

## 1. Simple Explanation

Prompt chaining means breaking a big task into smaller steps. Each step is handled by one LLM call. The output of one LLM becomes the input for the next LLM.

Think of it like a factory assembly line - each station does one specific job.

## 2. Why It Matters (Interview + Real World)

- **Problem it solves**: Complex tasks are hard for one LLM call. Breaking them into steps makes each part easier and more accurate.
- **Why companies use it**: Better control over quality. Each step can be optimized separately.
- **Why interviewers ask**: Shows you understand how to decompose problems and build reliable AI systems.

## 3. Very Simple Healthcare Example

Patient asks: "I feel sick, what should I do?"
- Step 1: LLM identifies symptoms → "chest pain, shortness of breath"
- Step 2: LLM checks urgency → "Emergency - call 911"
- Step 3: LLM creates action plan → "Go to ER immediately"

## 4. Step-by-Step Workflow

1. User enters a complex question
2. First LLM processes and generates partial answer
3. Output goes to second LLM for refinement
4. Second LLM output goes to third LLM
5. Final LLM produces complete answer
6. System returns result to user

## 5. Where It Fits in the System

- **AI Layer**: Agent Orchestrator coordinates the chain
- **Microservices**: Each LLM call can be a separate service
- **RAG**: Can be used between steps to fetch knowledge

## 6. Common Interview Questions

**Q1: When would you use prompt chaining instead of one big prompt?**
A: When the task has clear steps, when you need better accuracy per step, or when you want to optimize each part separately.

**Q2: What's the downside of prompt chaining?**
A: More API calls = higher cost and slower response time. Also harder to debug.

**Q3: How is this different from agents?**
A: Prompt chaining follows fixed steps. Agents decide their own steps dynamically.

## 7. Quick Revision Summary

- Chain = multiple LLM calls in sequence
- Each step does one specific task
- Output of step 1 → input of step 2
- Fixed path, predictable flow
- Better accuracy but higher cost

---

# 2. Routing

## Diagram

```
                    Input
                      ↓
              ┌───────────────┐
              │  Router LLM   │  (Classifies task)
              │  "Which expert│
              │   to use?"    │
              └───────┬───────┘
                      ↓
        ┌─────────────┼─────────────┐
        ↓             ↓             ↓
   ┌────────┐    ┌────────┐    ┌────────┐
   │ LLM 1  │    │ LLM 2  │    │ LLM 3  │
   │Medical │    │Billing │    │Schedule│
   │Expert  │    │Expert  │    │Expert  │
   └───┬────┘    └───┬────┘    └───┬────┘
       └─────────────┼─────────────┘
                     ↓
                  Output
```

**Healthcare Example:**
```
"I need to refill my prescription"
            ↓
    ┌──────────────┐
    │ Router LLM   │ → Analyzes: "This is medical"
    └──────┬───────┘
           ↓
    ┌──────────────┐
    │ Medical Agent│ → Handles prescription refill
    └──────────────┘
```

## 1. Simple Explanation

Routing means using one LLM to decide which specialist LLM should handle the task. Like a receptionist directing patients to the right doctor.

The router classifies the task and picks the best expert.

## 2. Why It Matters (Interview + Real World)

- **Problem it solves**: Different tasks need different expertise. One general model isn't always best.
- **Why companies use it**: Cost savings (use cheaper models for simple tasks) and better accuracy (specialists are better at their domain).
- **Why interviewers ask**: Tests understanding of system design and cost optimization.

## 3. Very Simple Healthcare Example

Patient question comes in → Router LLM analyzes it:
- "Billing question" → Routes to Billing Agent
- "Symptom check" → Routes to Medical Assistant Agent
- "Appointment" → Routes to Scheduling Agent

## 4. Step-by-Step Workflow

1. User submits a request
2. Router LLM analyzes the request type
3. Router classifies: medical, billing, or scheduling
4. Router sends to appropriate specialist LLM
5. Specialist LLM processes the request
6. Result returns to user

## 5. Where It Fits in the System

- **AI Layer**: AI Engine Service with multiple specialized agents
- **Agent Orchestrator**: Router acts as traffic controller
- **Microservices**: Each specialist can be a separate service

## 6. Common Interview Questions

**Q1: How does routing save money?**
A: You can use cheaper/smaller models for simple tasks and expensive/large models only for complex tasks.

**Q2: What if the router makes a wrong decision?**
A: Add fallback logic, use confidence scores, or have a "general" expert as backup.

**Q3: Routing vs Prompt Chaining - what's the difference?**
A: Routing picks ONE path. Chaining goes through ALL steps in sequence.

## 7. Quick Revision Summary

- One router LLM decides which expert to use
- Different specialists for different tasks
- Saves cost by using right-sized models
- Router classifies, then delegates
- Only ONE specialist handles each request

---

# 3. Parallelization

## Diagram

```
                    Input
                      ↓
              ┌───────────────┐
              │  Code Splits  │
              │  into 3 tasks │
              └───────┬───────┘
                      ↓
        ┌─────────────┼─────────────┐
        ↓             ↓             ↓
   ┌────────┐    ┌────────┐    ┌────────┐
   │ LLM 1  │    │ LLM 2  │    │ LLM 3  │
   │Task A  │    │Task B  │    │Task C  │
   │        │    │        │    │        │
   └───┬────┘    └───┬────┘    └───┬────┘
       └─────────────┼─────────────┘
                     ↓
              ┌───────────────┐
              │ Code Combines │
              │   Results     │
              └───────┬───────┘
                      ↓
                   Output
```

**Healthcare Example:**
```
"Analyze patient's complete health status"
                ↓
        [Code splits task]
                ↓
    ┌───────────┼───────────┐
    ↓           ↓           ↓
[Blood Test] [X-Ray]  [Medication]
  Analysis    Review    History
    ↓           ↓           ↓
    └───────────┼───────────┘
                ↓
        [Code combines]
                ↓
    Complete Health Report
```

## 1. Simple Explanation

Parallelization means breaking a task into multiple parts and running them all at the same time using different LLMs. Then combining the results.

Like having 3 chefs cook different dishes simultaneously for one meal.

## 2. Why It Matters (Interview + Real World)

- **Problem it solves**: Speed. Instead of waiting for tasks to finish one by one, do them all at once.
- **Why companies use it**: Faster responses, better user experience, can handle complex multi-part tasks.
- **Why interviewers ask**: Tests understanding of concurrency and system performance optimization.

## 3. Very Simple Healthcare Example

Patient needs full health assessment:
- LLM 1: Analyzes blood test results (parallel)
- LLM 2: Reviews X-ray images (parallel)
- LLM 3: Checks medication history (parallel)
→ Code combines all three reports into one summary

## 4. Step-by-Step Workflow

1. User submits complex request
2. Code splits task into 3 independent parts
3. Three LLMs process parts simultaneously
4. All three finish around the same time
5. Code aggregates the three outputs
6. Combined result returned to user

## 5. Where It Fits in the System

- **AI Layer**: Multiple agents run concurrently
- **Microservices**: Each parallel task can be a separate service call
- **Agent Orchestrator**: Manages parallel execution

## 6. Common Interview Questions

**Q1: When should you use parallelization?**
A: When tasks are independent and don't depend on each other's results. When speed matters more than cost.

**Q2: What's the challenge with parallelization?**
A: Combining results can be tricky. Also, if one task fails, you need error handling for all.

**Q3: Parallelization vs Routing?**
A: Parallelization runs MULTIPLE LLMs at once. Routing picks ONE LLM to run.

## 7. Quick Revision Summary

- Multiple LLMs run at the same time
- Code splits the task, code combines results
- Much faster than sequential processing
- Tasks must be independent
- Higher cost but better speed

---

# 4. Orchestrator-Worker

## Diagram

```
                    Input
                      ↓
          ┌───────────────────────┐
          │  Orchestrator LLM     │
          │  "Break down task     │
          │   into subtasks"      │
          └───────────┬───────────┘
                      ↓
        ┌─────────────┼─────────────┐
        ↓             ↓             ↓
   ┌────────┐    ┌────────┐    ┌────────┐
   │Worker 1│    │Worker 2│    │Worker 3│
   │  LLM   │    │  LLM   │    │  LLM   │
   │Subtask │    │Subtask │    │Subtask │
   └───┬────┘    └───┬────┘    └───┬────┘
       └─────────────┼─────────────┘
                     ↓
          ┌───────────────────────┐
          │  Orchestrator LLM     │
          │  "Combine results"    │
          └───────────┬───────────┘
                      ↓
                   Output
```

**Healthcare Example:**
```
"Create complete treatment plan"
            ↓
    ┌──────────────────┐
    │ Orchestrator LLM │ → Decides: Need diagnosis,
    │                  │   medication, lifestyle plan
    └────────┬─────────┘
             ↓
    ┌────────┼────────┐
    ↓        ↓        ↓
[Worker 1][Worker 2][Worker 3]
Diagnosis  Medicine  Lifestyle
    ↓        ↓        ↓
    └────────┼────────┘
             ↓
    ┌──────────────────┐
    │ Orchestrator LLM │ → Combines into
    │                  │   final plan
    └──────────────────┘
```

## 1. Simple Explanation

An orchestrator LLM breaks down a complex task into smaller tasks. Worker LLMs do each small task. Then the orchestrator LLM combines all results.

Like a project manager (orchestrator) assigning work to team members (workers).

## 2. Why It Matters (Interview + Real World)

- **Problem it solves**: Complex tasks need intelligent breakdown. An LLM can decide the best way to split work.
- **Why companies use it**: More flexible than code-based splitting. The orchestrator adapts to different problems.
- **Why interviewers ask**: Shows understanding of dynamic task decomposition and multi-agent systems.

## 3. Very Simple Healthcare Example

Patient: "Create my complete treatment plan"
- Orchestrator LLM: Decides to split into diagnosis, medication, lifestyle
- Worker 1: Generates diagnosis summary
- Worker 2: Recommends medications
- Worker 3: Suggests lifestyle changes
- Orchestrator LLM: Combines into final treatment plan

## 4. Step-by-Step Workflow

1. User submits complex request
2. Orchestrator LLM analyzes and breaks into subtasks
3. Orchestrator assigns subtasks to worker LLMs
4. Workers process their tasks in parallel
5. Workers return results to orchestrator
6. Orchestrator LLM synthesizes final answer
7. Result returned to user

## 5. Where It Fits in the System

- **AI Layer**: Agent Orchestrator pattern
- **Multi-Agent System**: One manager, multiple workers
- **Microservices**: Each worker can be independent service

## 6. Common Interview Questions

**Q1: Orchestrator-Worker vs Parallelization - what's different?**
A: Orchestrator uses an LLM to decide how to split work. Parallelization uses code to split work.

**Q2: Why use an LLM orchestrator instead of code?**
A: LLM can adapt to different problems dynamically. Code follows fixed rules.

**Q3: What's the risk of using an LLM orchestrator?**
A: Less predictable. The orchestrator might split tasks differently each time. Harder to guarantee behavior.

## 7. Quick Revision Summary

- LLM orchestrator breaks down tasks
- Multiple worker LLMs do the work
- Orchestrator combines results
- More flexible than code-based splitting
- Less predictable but more adaptive

---

# 5. Evaluator-Optimizer (Validation Pattern)

## Diagram

```
        Input
          ↓
    ┌──────────────┐
    │ Generator LLM│ → Creates answer
    └──────┬───────┘
           ↓
    ┌──────────────┐
    │Evaluator LLM │ → Checks quality
    └──────┬───────┘
           ↓
      Good or Bad?
           ↓
    ┌──────┴──────┐
    ↓             ↓
  GOOD          BAD
    ↓             ↓
  Output    ┌─────────────┐
            │  Feedback   │
            │  + Reason   │
            └──────┬──────┘
                   ↓
            [Loop back to Generator]
```

**Detailed Flow:**
```
┌─────────────────────────────────────────┐
│                                         │
│  ┌──────────────┐                      │
│  │ Generator LLM│                      │
│  │ "Take 500mg  │                      │
│  │  aspirin"    │                      │
│  └──────┬───────┘                      │
│         ↓                               │
│  ┌──────────────┐                      │
│  │Evaluator LLM │                      │
│  │ "REJECT:     │                      │
│  │  Too high!"  │                      │
│  └──────┬───────┘                      │
│         ↓                               │
│  [Feedback Loop] ←──────────────────┐  │
│         ↓                            │  │
│  ┌──────────────┐                   │  │
│  │ Generator LLM│                   │  │
│  │ "Take 81mg   │                   │  │
│  │  aspirin"    │                   │  │
│  └──────┬───────┘                   │  │
│         ↓                            │  │
│  ┌──────────────┐                   │  │
│  │Evaluator LLM │                   │  │
│  │ "ACCEPT ✓"   │                   │  │
│  └──────┬───────┘                   │  │
│         ↓                            │  │
│      Output ─────────────────────────┘  │
│                                         │
└─────────────────────────────────────────┘
```

## 1. Simple Explanation

One LLM generates an answer. A second LLM checks if the answer is good. If not good, it sends feedback and the first LLM tries again.

Like a writer and an editor working together.

## 2. Why It Matters (Interview + Real World)

- **Problem it solves**: LLMs make mistakes. Having a second LLM check the work improves accuracy.
- **Why companies use it**: Critical for production systems. Reduces errors and hallucinations.
- **Why interviewers ask**: Shows you understand quality control and building reliable AI systems.

## 3. Very Simple Healthcare Example

Generator LLM: "Patient should take 500mg aspirin daily"
Evaluator LLM: "REJECT - Dose too high, standard is 81mg"
Generator LLM: "Patient should take 81mg aspirin daily"
Evaluator LLM: "ACCEPT - Correct dosage"

## 4. Step-by-Step Workflow

1. User submits request
2. Generator LLM creates answer
3. Evaluator LLM checks the answer
4. If good → return answer to user
5. If bad → evaluator explains why
6. Generator LLM tries again with feedback
7. Loop continues until evaluator accepts
8. Final answer returned to user

## 5. Where It Fits in the System

- **AI Layer**: Output validation and guardrails
- **Safety Layer**: Prevents bad outputs from reaching users
- **Agent Pattern**: Feedback loop between two agents

## 6. Common Interview Questions

**Q1: Why not just use one better LLM instead of two?**
A: Generating and evaluating are different skills. Specialized prompts for each work better. Also adds safety layer.

**Q2: What if the evaluator keeps rejecting forever?**
A: Set a maximum retry limit (e.g., 3 attempts). Then either return best attempt or error message.

**Q3: Where is this pattern most critical?**
A: Healthcare, finance, legal - anywhere mistakes are costly or dangerous.

## 7. Quick Revision Summary

- Two LLMs: generator and evaluator
- Evaluator checks generator's work
- Feedback loop until answer is good
- Greatly improves accuracy
- Most common pattern for production systems

---

# 6. Agent Pattern (Autonomous Agents)

## Diagram

```
        Human/User
            ↓
        [Goal/Task]
            ↓
    ┌───────────────┐
    │  Agent LLM    │ ←──────────┐
    │  (Decides     │            │
    │   own path)   │            │
    └───────┬───────┘            │
            ↓                    │
    ┌───────────────┐            │
    │  Take Action  │            │
    │  (Use tools,  │            │
    │   call APIs)  │            │
    └───────┬───────┘            │
            ↓                    │
    ┌───────────────┐            │
    │  Environment  │            │
    │  (Returns     │            │
    │   feedback)   │            │
    └───────┬───────┘            │
            ↓                    │
    [Analyze Feedback] ──────────┘
            ↓
    Goal Achieved?
            ↓
    ┌───────┴───────┐
    ↓               ↓
   YES             NO
    ↓               ↓
  Output      [Continue Loop]
```

**Healthcare Example:**
```
Patient: "Help me manage my diabetes"
            ↓
    ┌──────────────┐
    │  Agent LLM   │
    └──────┬───────┘
           ↓
    Decides: "Check patient history first"
           ↓
    [Retrieves medical records]
           ↓
    Decides: "Search latest guidelines"
           ↓
    [Searches medical database]
           ↓
    Decides: "Calculate medication adjustment"
           ↓
    [Runs calculation]
           ↓
    Decides: "Schedule follow-up"
           ↓
    [Books appointment]
           ↓
    Decides: "Goal complete"
           ↓
    Returns comprehensive diabetes management plan
```

**Key Difference:**
```
WORKFLOW:              AGENT:
Fixed path             Dynamic path
Step 1 → 2 → 3        Agent decides each step
Predictable            Unpredictable
```

## 1. Simple Explanation

An agent is an LLM that decides its own steps. It can interact with the environment, get feedback, and keep trying until it solves the problem.

No fixed workflow. The agent plots its own path.

## 2. Why It Matters (Interview + Real World)

- **Problem it solves**: Can handle complex, unpredictable problems that don't fit fixed workflows.
- **Why companies use it**: Solves problems that are too complex for predefined steps. More powerful and flexible.
- **Why interviewers ask**: Tests understanding of advanced AI systems and their tradeoffs (power vs control).

## 3. Very Simple Healthcare Example

Patient: "I need help managing my diabetes"
Agent decides its own steps:
- Checks patient history
- Searches medical guidelines
- Calculates medication adjustments
- Schedules follow-up
- Keeps going until patient's plan is complete

## 4. Step-by-Step Workflow

1. User gives agent a goal
2. Agent analyzes what it needs to do
3. Agent takes action (calls tool, searches data, etc.)
4. Agent gets feedback from environment
5. Agent decides next action based on feedback
6. Repeat steps 3-5 until goal achieved
7. Agent returns final result

## 5. Where It Fits in the System

- **AI Layer**: Autonomous agent with tool access
- **Agent Orchestrator**: Manages agent execution
- **RAG, Tools, APIs**: Agent can use all of these

## 6. Common Interview Questions

**Q1: Agent vs Workflow - what's the key difference?**
A: Workflow has fixed steps. Agent decides its own steps dynamically.

**Q2: What are the risks of using agents?**
A: Unpredictable cost, unpredictable time, unpredictable output quality, might not finish the task.

**Q3: How do you make agents safe for production?**
A: Monitoring (watch what it's doing), guardrails (limit what it can do), timeouts (stop if too long), cost limits.

## 7. Quick Revision Summary

- Agent decides its own path
- No fixed workflow
- Can interact with environment repeatedly
- Very powerful but unpredictable
- Needs monitoring and guardrails

---

# Comparison: Workflows vs Agents

## Visual Comparison

```
WORKFLOWS (Patterns 1-5)
═══════════════════════════════════════
Input → [Step 1] → [Step 2] → [Step 3] → Output
        Fixed      Fixed      Fixed
        
Characteristics:
✓ Predictable path
✓ Known steps
✓ Controlled flow
✓ Easier to debug


AGENTS (Pattern 6)
═══════════════════════════════════════
                ┌─────────────┐
                │             │
Input → [Agent] ┼→ [Action 1] │
         ↑  ↓   │  [Action 2] │
         │  └───┼→ [Action ?] │
         │      │  [Action ?] │
         └──────┼─ [Feedback] │
                │             │
                └─────────────┘
                       ↓
                    Output
                    
Characteristics:
? Unpredictable path
? Unknown steps
? Dynamic flow
? Harder to debug
```

## Workflows (Patterns 1-5)

**Characteristics:**
- Fixed steps
- Predictable path
- Known cost and time
- Easier to debug
- More reliable

**When to use:**
- Production systems with strict requirements
- When you know the steps needed
- When predictability matters

## Agents (Pattern 6)

**Characteristics:**
- Dynamic steps
- Unpredictable path
- Unknown cost and time
- Harder to debug
- More powerful

**When to use:**
- Complex, open-ended problems
- When you can't predict all scenarios
- When flexibility matters more than predictability

---

# Key Challenges with Agents

## Visual Representation of Agent Challenges

```
┌─────────────────────────────────────────────────────┐
│              AGENT CHALLENGES                        │
├─────────────────────────────────────────────────────┤
│                                                      │
│  1. UNPREDICTABLE PATH                              │
│     Input → [?] → [?] → [?] → [?] → Output?        │
│     Don't know: order, tasks, duration              │
│                                                      │
│  2. UNPREDICTABLE COST                              │
│     API Call 1: $0.01                               │
│     API Call 2: $0.01                               │
│     API Call ?: $0.01                               │
│     API Call ?: $0.01                               │
│     Total: $??? (Could be $1 or $100)               │
│                                                      │
│  3. UNPREDICTABLE QUALITY                           │
│     Attempt 1: ❌ Wrong answer                      │
│     Attempt 2: ❌ Incomplete                        │
│     Attempt 3: ❌ Hallucination                     │
│     Attempt 4: ✓ Good answer (maybe?)              │
│                                                      │
└─────────────────────────────────────────────────────┘
```

## 1. Unpredictable Path
- Don't know what order tasks happen
- Don't know which tasks will happen
- Hard to guarantee specific behavior

## 2. Unpredictable Cost
- Don't know how many API calls
- Could run up large bills
- Need cost limits and monitoring

## 3. Unpredictable Quality
- No guarantee of good output
- Might not complete the task
- Needs validation and guardrails

---

# Solutions: Monitoring & Guardrails

## Visual Architecture

```
┌─────────────────────────────────────────────────────────┐
│                    SAFE AGENT SYSTEM                     │
├─────────────────────────────────────────────────────────┤
│                                                          │
│  ┌────────────────────────────────────────────────┐    │
│  │              MONITORING LAYER                   │    │
│  │  ┌──────────┐  ┌──────────┐  ┌──────────┐     │    │
│  │  │ Cost     │  │ Time     │  │ Quality  │     │    │
│  │  │ Tracker  │  │ Tracker  │  │ Checker  │     │    │
│  │  └────┬─────┘  └────┬─────┘  └────┬─────┘     │    │
│  │       └─────────────┼─────────────┘            │    │
│  └───────────────────┬─┬──────────────────────────┘    │
│                      ↓ ↓                                │
│  ┌────────────────────────────────────────────────┐    │
│  │                AGENT LLM                        │    │
│  │         (Doing its work)                        │    │
│  └────────────────────────────────────────────────┘    │
│                      ↓ ↓                                │
│  ┌───────────────────┬─┬──────────────────────────┐    │
│  │              GUARDRAILS LAYER                   │    │
│  │  ┌──────────┐  ┌──────────┐  ┌──────────┐     │    │
│  │  │ Max Cost │  │ Timeout  │  │ Action   │     │    │
│  │  │ $10 limit│  │ 60 sec   │  │ Limits   │     │    │
│  │  └──────────┘  └──────────┘  └──────────┘     │    │
│  └────────────────────────────────────────────────┘    │
│                                                          │
└─────────────────────────────────────────────────────────┘
```

## Monitoring
Watch what agents are doing in real-time:
- Track API calls and costs
- See agent reasoning steps
- Understand agent interactions
- Debug when things go wrong

**Tools:** OpenAI SDK tracing, LangSmith, Application Insights

## Guardrails
Set boundaries on what agents can do:
- Maximum retry attempts
- Maximum cost limits
- Time limits (timeouts)
- Restricted actions
- Output validation

**Purpose:** Ensure agents behave safely and within boundaries

## Example Implementation

```
┌─────────────────────────────────────┐
│  Agent starts task                  │
└────────────┬────────────────────────┘
             ↓
┌─────────────────────────────────────┐
│  Guardrail Check:                   │
│  ✓ Cost < $10?                      │
│  ✓ Time < 60 sec?                   │
│  ✓ Action allowed?                  │
└────────────┬────────────────────────┘
             ↓
        ┌────┴────┐
        ↓         ↓
      PASS      FAIL
        ↓         ↓
   [Continue]  [Stop & Alert]
        ↓
   [Monitor logs everything]
```

---

# Healthcare Platform: Where Each Pattern Fits

## System Architecture with Patterns

```
┌─────────────────────────────────────────────────────────────┐
│           SMART HEALTHCARE AI PLATFORM                       │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│  Patient Input                                              │
│       ↓                                                      │
│  ┌────────────────────────────────────────┐                │
│  │  ROUTING PATTERN                        │                │
│  │  Router decides: Medical/Billing/Admin  │                │
│  └────────┬───────────────────────────────┘                │
│           ↓                                                  │
│  ┌────────┼────────┬────────────┐                          │
│  ↓        ↓        ↓            ↓                          │
│                                                              │
│  MEDICAL PATH (Prompt Chaining)                             │
│  ┌──────────────────────────────────────┐                  │
│  │ Step 1: Symptom Analysis             │                  │
│  │    ↓                                  │                  │
│  │ Step 2: Risk Assessment               │                  │
│  │    ↓                                  │                  │
│  │ Step 3: Recommendation                │                  │
│  └──────────────────────────────────────┘                  │
│           ↓                                                  │
│  ┌──────────────────────────────────────┐                  │
│  │ EVALUATOR PATTERN                     │                  │
│  │ Validate medical recommendation       │                  │
│  └──────────────────────────────────────┘                  │
│                                                              │
│  COMPLEX ASSESSMENT (Parallelization)                       │
│  ┌──────────────────────────────────────┐                  │
│  │  Lab Analysis  │  Imaging  │  History│                  │
│  │       ↓        │     ↓     │    ↓    │                  │
│  │  [Combine Results]                    │                  │
│  └──────────────────────────────────────┘                  │
│                                                              │
│  TREATMENT PLANNING (Orchestrator-Worker)                   │
│  ┌──────────────────────────────────────┐                  │
│  │  Orchestrator breaks down plan        │                  │
│  │       ↓           ↓          ↓        │                  │
│  │  Diagnosis  Medication  Lifestyle     │                  │
│  │       ↓           ↓          ↓        │                  │
│  │  Orchestrator combines plan           │                  │
│  └──────────────────────────────────────┘                  │
│                                                              │
│  COMPLEX CARE (Agent Pattern)                               │
│  ┌──────────────────────────────────────┐                  │
│  │  Agent autonomously manages           │                  │
│  │  complete patient care journey        │                  │
│  │  (with monitoring & guardrails)       │                  │
│  └──────────────────────────────────────┘                  │
│                                                              │
└─────────────────────────────────────────────────────────────┘
```

## Prompt Chaining
- **Use case**: Patient triage workflow
- **Example**: Symptom analysis → Risk assessment → Appointment scheduling

## Routing
- **Use case**: Directing patient queries
- **Example**: Medical questions → Medical Agent, Billing → Billing Agent

## Parallelization
- **Use case**: Comprehensive health assessment
- **Example**: Analyze labs + Review imaging + Check medications simultaneously

## Orchestrator-Worker
- **Use case**: Complex treatment planning
- **Example**: Orchestrator breaks down treatment into diagnosis, medication, lifestyle plans

## Evaluator-Optimizer
- **Use case**: Medication recommendations
- **Example**: Generator suggests dosage → Evaluator checks safety → Loop until safe

## Agent Pattern
- **Use case**: Complex patient care coordination
- **Example**: Agent autonomously manages patient's complete care journey

---

# Interview Preparation: Key Takeaways

## What Interviewers Want to Hear

1. **Understanding tradeoffs**: "Workflows are predictable but rigid. Agents are flexible but unpredictable."

2. **Practical application**: "For our healthcare platform, I'd use evaluator pattern for medication recommendations because safety is critical."

3. **Production readiness**: "Agents need monitoring and guardrails. I'd set cost limits and timeouts."

4. **Pattern selection**: "I'd choose prompt chaining when steps are clear, and agents when the problem is open-ended."

## Common Mistakes to Avoid

- Don't say "agents are always better" - they have tradeoffs
- Don't ignore cost and monitoring concerns
- Don't confuse routing with parallelization
- Don't forget about guardrails and safety

---

# Quick Reference Table

| Pattern | Fixed Steps? | Who Decides? | Speed | Cost | Use When |
|---------|-------------|--------------|-------|------|----------|
| Prompt Chaining | Yes | Developer | Slow | Medium | Clear sequential steps |
| Routing | Yes | LLM Router | Fast | Low | Different task types |
| Parallelization | Yes | Code | Fast | High | Independent tasks |
| Orchestrator-Worker | No | LLM Orchestrator | Medium | High | Complex decomposition |
| Evaluator-Optimizer | Yes | Evaluator LLM | Slow | High | Quality critical |
| Agent | No | Agent LLM | Unknown | Unknown | Open-ended problems |

---

# Final Summary

**5 Workflow Patterns:**
1. Prompt Chaining - Sequential LLM calls
2. Routing - Pick the right specialist
3. Parallelization - Run multiple tasks at once
4. Orchestrator-Worker - LLM breaks down work
5. Evaluator-Optimizer - Check and improve quality

**1 Agent Pattern:**
6. Autonomous Agent - Decides its own path

**Key Principle:**
- Use workflows when you need control
- Use agents when you need flexibility
- Always add monitoring and guardrails for production

---

**End of Guide**
